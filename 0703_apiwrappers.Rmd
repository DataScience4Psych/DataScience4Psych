```{r include = FALSE}
source("common.R")
ds4p_funyoutube <- read.csv("admin/csv/ds4p_funyoutube.csv", sep = "")
ds4p_urls <- read.csv("./admin/csv/ds4p_urls.csv")
```

# Use API-wrapping packages {#api-wrappers}

This section explores how to use R packages that wrap APIs, allowing easy access to web data. We'll cover various approaches from simple downloads to more complex API interactions. This content builds on Jenny Bryan's stat545 materials, with significant updates and additions to reflect current best practices. For a more in-depth look at APIs, check out the [API chapter](https://r4ds.had.co.nz/apis.html) in the R for Data Science book. For a huge list of free apis to play with, check out [this list](https://free-apis.github.io/#/)



```{r, echo=FALSE}
try_include_tweet("https://twitter.com/rfunctionaday/status/1381848183928729600")
```

## The Data Acquisition Spectrum

When it comes to obtaining data from the internet, we can categorize methods into four main type
* *Direct Download*: Grabbing readily available flat files (CSV, XLS, etc.)
* *Wrapped API Access*: Using R packages designed for specific APIs
* *Raw API Interaction*: Crafting custom queries for APIs
* *Web Scraping*: Extracting data embedded in HTML structures

We'll focus primarily on the second method, but now you know about the full spectrum of options at your disposal.
For a comprehensive list of R tools for interacting with the internet, check out the [rOpenSci repository]( https://github.com/ropensci/webservices). These tools include packages for APIs, scraping, and more.


## Direct Download

In the simplest case, the data you need is already on the internet in a tabular format. Effectively, you just need to click and download whatever data you need. There are a couple of strategies here:

* Use `read.csv` or `readr::read_csv` to read the data straight into R.
* Use the command line program `curl` to do that work, and place it in a `Makefile` or shell script (see the [section on `make`](#automation-overview) for more on this).

The second case is most useful when the data you want has been provided in a format that needs cleanup. For example, the World Value Survey makes several datasets available as Excel sheets. The safest option here is to download the `.xls` file, then read it into R with `readxl::read_excel()` or something similar. An exception to this is data provided as Google Spreadsheets, which can be read straight into R using the [`googlesheets`](https://github.com/jennybc/googlesheets) package.

### From rOpenSci web services page

From rOpenSci's [CRAN Task View: Web Technologies and Services](https://github.com/ropensci/webservices):

* `downloader::download()` for SSL.
* `curl::curl()` for SSL.
* `httr::GET` data read this way needs to be parsed later with `read.table()`.
* `rio::import()` can "read a number of common data formats directly from an `https://` URL".  Isn't that very similar to the previous?

What about packages that install data?

## Data supplied on the web

Many times, the data that you want is not already organized into one or a few tables that you can read directly into R. More frequently, you find this data is given in the form of an API. **A**pplication **P**rogramming **I**nterfaces (APIs) are descriptions of the kind of requests that can be made of a certain piece of software, and descriptions of the kind of answers that are returned.

Many sources of data -- databases, websites, services -- have made all (or part) of their data available via APIs over the internet. Computer programs ("clients") can make requests of the server, and the server will respond by sending data (or an error message). This client can be many kinds of other programs or websites, including R running from your laptop.

## Streamlined Data Retrieval with API Wrappers

Many common web services and APIs have been "wrapped", i.e. R functions have been written around them which send your query to the server and format the response. This is a great way to get started with APIs, as you don't need to worry about the details of the API itself. You can just focus on the data you want to get.

API-wrapping packages act as intermediaries between your R environment and web services. They handle the nitty-gritty of API calls, authentication, and data parsing, allowing you to focus on analysis rather than data acquisition logistics. These packages are especially useful for beginners, as they abstract away the complexities of web service interaction. For added bonuses, they often ensure that the data you receive is actually from the API you intended to query, and they provide a structured reproducible way to access the data. 



### Case Study: Ornithological Data with rebird

Let's dive into a practical example using the [rebird](https://github.com/ropensci/rebird) package, which interfaces with the [eBird](http://ebird.org/content/ebird/) database. eBird lets birders upload sightings of birds, and allows everyone access to those data. rebird makes it easy to access this data from R (as long as you request an API key)

```{r message = FALSE, warning = FALSE,error=TRUE}
library(tidyverse)
library(kableExtra)
library(rebird)
```

First, let's fetch recent bird sightings from a specific location:


#### Search birds by geography

The eBird website categorizes some popular locations as "Hotspots". These are areas where there are both lots of birds and lots of birders. One such location is at Iona Island, near Vancouver. You can see data for this Hotspot at [http://ebird.org/ebird/hotspot/L261851](http://ebird.org/ebird/hotspot/L261851).

At that link, you will see a page like this:

```{r ebird-iona-island, echo = FALSE, fig.cap = "Iona Island", out.width = "80%"}
knitr::include_graphics("img/Iona_island.png")
```

The data already looks to be organized in a data frame! rebird allows us to read these data directly into R (the ID code for Iona Island is **"L261851"**). Note that this requires an API key which you have to request from ebird via this [link](https://ebird.org/api/request) . I have set my key as an environment variable. However you can set it as a global variable in your R session. Like this:

<!--TODO: The following chunks are broken; ebird now requires an API key.-->
```{r eval = FALSE,error=TRUE,include=TRUE}
ebirdkey <- "SECRET API KEY"
```
```{r message=FALSE, warning=FALSE, include=FALSE}
ebirdkey <- read.table("admin/secrets/ebird_api_key.txt", quote = "\"", comment.char = "")[1, 1]
```

```{r eval = TRUE,error=TRUE, cache=TRUE}
ebirdregion(loc = "L261851", key = ebirdkey) %>%
  head() %>%
  kable()
```

We can use the function `ebirdgeo()` to get a list for an area (note that South and West are negative):

```{r results = 'asis', eval = TRUE,error=TRUE,cache=TRUE}
vanbirds <- ebirdgeo(lat = 49.2500, lng = -123.1000, key = ebirdkey)
vanbirds %>%
  head() %>%
  kable()
```

**Note**: Check the defaults on this function (e.g. radius of circle, time of year).

We can also search by "region", which refers to short codes which serve as common shorthands for different political units. For example, France is represented by the letters **FR**.

```{r eval = TRUE,error=TRUE,cache=TRUE}
frenchbirds <- ebirdregion("FR", key = ebirdkey)
frenchbirds %>%
  head() %>%
  kable()
```

Find out *when* a bird has been seen in a certain place! Choosing a name from `vanbirds` above (the Bald Eagle):

```{r eval = TRUE,cache=TRUE}
eagle <- ebirdgeo(
  species = "baleag",
  lat = 42, lng = -76, key = ebirdkey
)
eagle %>%
  head() %>%
  kable()
```

rebird **knows where you are**:

```{r eval = TRUE,error=TRUE,cache=TRUE}
ebirdgeo(species = "rolhaw", key = ebirdkey)
```

### Searching geographic info: geonames {#geonames}

[rOpenSci](https://ropensci.org) has a package called [geonames](https://docs.ropensci.org/geonames/) for accessing the [GeoNames API](https://www.geonames.org). First, install the geonames package from CRAN and load it.

```{r message = FALSE, warning = FALSE,error=TRUE}
# install.packages("geonames")
library(geonames)
```

The [geonames package website](https://docs.ropensci.org/geonames/) tells us that there are a few things we need to do before we can use geonames to access the GeoNames API:

1. Go to [the GeoNames site](https://www.geonames.org/login) and create a new user account.
1. Check your email and follow the instructions to activate your account.
1. You have to manually enable the free web services for your account (Note! You must be logged into your GeoNames account).
1. Tell R your GeoNames username.

To do the last step, we could run this line in R...

```r
options(geonamesUsername="my_user_name")

```

...but this is insecure. We don't want to risk committing this line and pushing it to our public GitHub page!

Instead, we can add this line to our `.Rprofile` so it will be hidden. One way to edit your `.Rprofile` is with the helper function `edit_r_profile()` from the [usethis][usethis-web] package. Install/load the usethis package and run `edit_r_profile()` in the R Console:

```{r message = FALSE, warning = FALSE, eval = TRUE,error=TRUE}
# install.packages("usethis")
library(usethis)
edit_r_profile()
```

This will open up your `.Rprofile` file. Add `options(geonamesUsername="my_user_name")` on a new line (replace "my_user_name" with your GeoNames username).

**Important**: Make sure your `.Rprofile` ends with a blank line!

Save the file, close it, and restart R. Now we're ready to start using geonames to search the GeoNames API.

(Also see the [Cache credentials for HTTPS](https://happygitwithr.com/credential-caching.html) chapter of [Happy Git and GitHub for the useR](https://happygitwithr.com).)

#### Using GeoNames

What can we do? We can get access to lots of geographical information via the various [GeoNames WebServices](http://www.geonames.org/export/ws-overview.html).

```{r, eval = TRUE,error=TRUE}
countryInfo <- geonames::GNcountryInfo()
```

```{r eval = TRUE,error=TRUE,cache=TRUE}
glimpse(countryInfo)
```

This `countryInfo` dataset is very helpful for accessing the rest of the data because it gives us the standardized codes for country and language.

#### Remixing geonames

What are the cities of France?

```{r eval = TRUE,cache=TRUE}
francedata <- countryInfo %>%
  filter(countryName == "France")
```

```{r eval = TRUE,error=TRUE,cache=TRUE}
frenchcities <- with(francedata, GNcities(
  north = north, east = east,
  south = south, west = west,
  maxRows = 500
))
```

```{r eval = TRUE, cache=TRUE, error=TRUE}
glimpse(frenchcities)
```

### Wikipedia searching

We can use geonames to search for georeferenced Wikipedia articles. Here are those within 20 km of Rio de Janerio, comparing results for English-language Wikipedia (`lang = "en"`) and Portuguese-language Wikipedia (`lang = "pt"`):

```{r, eval = TRUE,error=TRUE}
rio_english <- geonames::GNfindNearbyWikipedia(
  lat = -22.9083, lng = -43.1964,
  radius = 20, lang = "en", maxRows = 500
)
rio_portuguese <- geonames::GNfindNearbyWikipedia(
  lat = -22.9083, lng = -43.1964,
  radius = 20, lang = "pt", maxRows = 500
)
```

```{r eval = TRUE,error=TRUE}
nrow(rio_english)
nrow(rio_portuguese)
```


### Is it a boy or a girl? gender-associated names throughout US history

The gender package allows you access to data on the gender of names in the US. Because names change gender over the years, the probability of a name belonging to a man or a woman also depends on the *year*.

First, install/load the gender package from CRAN. You may be prompted to also install the companion package, genderdata. Go ahead and say yes. If you don't see this message no need to worry, it is a one-time install.

```{r,error=TRUE}
# install.packages("gender")
# remotes::install_github("lmullen/genderdata")
library(gender)
```

Let's do some searches for the name Kelsey.

```{r,error=TRUE}
gender("Kelsey")
gender("Kelsey", years = 1940)
```

As you can see, the probability of a name belonging to a specific gender can change over time.

```{r plot, cache=TRUE}
df <- gender("Kelsey")

years <- c(df$year_min:df$year_max)

for (i in 1:length(years)) {
  df <- rbind(df, gender("Kelsey", years = years[i]))
}
df %>%
  filter(year_min == year_max) %>%
  ggplot(aes(year_min, proportion_male)) +
  geom_smooth(span = 0.1) +
  labs(
    title = "Proportion of men named Kelsey over time",
    x = "Year",
    y = "Proporiton Male"
  ) +
  ggthemes::theme_excel()
```


In contrast, the name Mason has been more consistently male.

```{r,error=TRUE, cache=TRUE}
gender("Mason")
gender("Mason", years = 1940)
```

```{r plotMason, cache=TRUE}
mason <- gender("Mason")
years <- c(mason$year_min:mason$year_max)

df <- rbind(df, gender("Mason"))

for (i in 1:length(years)) {
  df <- rbind(df, gender("Mason", years = years[i]))
}

df %>%
  filter(year_min == year_max & name == "Mason") %>%
  ggplot(aes(year_min, proportion_male)) +
  geom_point() +
  geom_smooth(span = 0.1) +
  labs(
    title = "Proportion of men named Mason over time",
    x = "Year",
    y = "Proporiton Male"
  ) +
  ggthemes::theme_excel()
```


And when we compare the two names, we see that Kelsey has changed a lot more over time than Mason.

```{r plotCompare, cache=TRUE}
df %>%
  filter(year_min == year_max) %>%
  ggplot(aes(year_min, proportion_male)) +
  geom_point() +
  geom_smooth(span = 0.1) +
  labs(
    title = "Proportion of men over time",
    x = "Year",
    y = "Proporiton Male"
  ) +
  ggthemes::theme_excel() +
  facet_wrap(~name)
```



## Conclusion

API-wrapping packages in R provide powerful tools for accessing diverse data sources. As you progress in your data science journey, mastering these tools will greatly expand the range of data available for your analyses. Remember to always check the terms of service for any API you use, and be mindful of rate limits and data usage policies.


```{r links1, child="admin/md/courselinks.md"}
```

```{r links2, child="admin/md/links.md"}
```
