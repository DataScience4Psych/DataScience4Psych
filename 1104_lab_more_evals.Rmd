# Lab: Modeling with multiple predictors {#lab10}

## Professor attractiveness and course evaluations, Pt. 2 {.unnumbered}

```{r include=FALSE}
library(tufte)
library(knitr)
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE, # for regression output
  digits = 2
)
knitr::opts_chunk$set(eval = FALSE)
```

In this lab, we revisit the professor evaluations data we modeled in the previous lab. In the last lab, we modeled evaluation scores using a single predictor at a time. However, this time we use multiple predictors to model evaluation scores.

If you don't remember the data, review the previous lab's introduction before continuing to the exercises.

## Getting started {.unnumbered}

### Packages {.unnumbered}

In this lab we will work with the **tidyverse**, **openintro**, and **broom** packages.

```{r eval = FALSE}
library(tidyverse)
library(broom)
library(openintro)
```

<!-- 
### Housekeeping

#### Git configuration / password caching

Configure your Git user name and email. If you cannot remember the instructions, refer to an earlier lab. Also remember that you can cache your password for a limited amount of time.

#### Project name

Update the name of your project to match the lab's title.

-->

## Warm up {.unnumbered}

Before we introduce the data, let's warm up with some simple exercises.

### YAML {.unnumbered}

Open the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.

### Commiting and pushing changes {.unnumbered}

- Go to the **Git** pane in your RStudio.
- View the **Diff** and confirm that you are happy with the changes.
- Add a commit message like "Update team name" in the **Commit message** box and hit **Commit**.
- Click on **Push**. This will prompt a dialogue box where you first need to enter your user name, and then your password.

## The data {.unnumbered}

The dataset we'll be using is called `evals` from the **openintro** package. Take a peek at the codebook with `?evals`.

## Exercises {.unnumbered}

### Part 1: Simple linear regression {.unnumbered}

1. Fit a linear model (one you have fit before): `m_bty`, predicting average
   professor evaluation `score` based on average beauty rating (`bty_avg`) only. Write the
   linear model, and note the $R^2$ and the adjusted $R^2$.

### Part 2: Multiple linear regression {.unnumbered}

2. Fit a linear model (one you have fit before): `m_bty_gen`, predicting average
   professor evaluation `score` based on average beauty rating (`bty_avg`) and `gender`.
   Write the linear model, and note the $R^2$ and the adjusted $R^2$.

3. Interpret the slope and intercept of `m_bty_gen` in context of the data.

4. What percent of the variability in `score` is explained by the model `m_bty_gen`.

5. What is the equation of the line corresponding to *just* male professors?

6. For two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?

7. How does the relationship between beauty and evaluation score vary between male and female professors?

8. How do the adjusted $R^2$ values of `m_bty_gen` and `m_bty` compare? What does this tell us about how useful `gender` is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.

9. Compare the slopes of `bty_avg` under the two models (`m_bty` and `m_bty_gen`). Has the addition of `gender` to the model changed the parameter estimate (slope) for `bty_avg`?

10. Create a new model called `m_bty_rank` with `gender` removed and `rank`  added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data.

### Part 3: The search for the best model {.unnumbered}

Going forward, only consider the following variables as potential predictors: `rank`, `ethnicity`, `gender`, `language`, `age`, `cls_perc_eval`, `cls_did_eval`, `cls_students`, `cls_level`, `cls_profs`, `cls_credits`, `bty_avg`.

11. Which variable, on its own, would you expect to be the worst predictor of evaluation scores? Why? *Hint:* Think about which variable would you expect to not have any association with the professor's score.

12. Check your suspicions from the previous exercise. Include the model output for that variable in your response.

13. Suppose you wanted to fit a full model with the variables listed above. If you are already going to include `cls_perc_eval` and `cls_students`, which variable should you not include as an additional predictor? Why?

14. Fit a full model with all predictors listed above (except for the one you decided to exclude) in the previous question.

15. Using backward-selection with adjusted R-squared as the selection criterion, determine the *best* model. You do not need to show all steps in your answer, just the output for the final model. Also, write out the linear model for predicting score based on the final model you settle on.

16. Interpret the slopes of one numerical and one categorical predictor based on your final model.

17. Based on your final model, describe the characteristics of a professor and course at University of Texas at Austin that would be associated with a high evaluation score.

18. Would you be comfortable generalizing your conclusions to apply to professors generally (at any university)? Why or why not?

```{r links, child="admin/md/courselinks.md"}
```
