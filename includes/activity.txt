Meme-tastic data science activity: OpenAI API + Tidyverse for grad students

Overview
- Goal: Learn to call OpenAI's API from R, handle and parse responses, and analyze the outputs inside a tidyverse workflow.
- Theme: Meme-inspired prompts to generate concise, educational, and humorous captions. Templates include classic memes like Doge, Distracted Boyfriend, Two-Button, Expanding Brain, Drake Hotline Bling, and Futurama Fry.
- Deliverables: A reproducible R workflow (script or R Markdown) that makes API calls, stores results in a tidy data frame, computes simple analytics, and visualizes outputs.

Learning objectives
- Practice making REST API calls to OpenAI from R (tidyverse-friendly workflow).
- Learn to structure prompts, pass them through a system prompt, and handle responses (text + usage metadata).
- Use dplyr, purrr, tidyr, and stringr to wrangle API results into tidy data frames.
- Analyze and compare outputs across multiple meme-style prompts (length, token usage, readability proxies).
- Create a simple “Memeboard” to showcase best-performing captions and potential improvements.

Prerequisites
- R and RStudio (or any editor with R support).
- Packages: tidyverse (dplyr, purrr, tidyr, ggplot2, readr), httr, jsonlite, stringr, possibly glue.
- OpenAI API key stored as an environment variable OPENAI_API_KEY (recommended) or read from an .Renviron file.
- Basic familiarity with the tidyverse and basic API concepts.

Setup (one-time)
- Install packages (if needed):
  - install.packages(c("tidyverse", "httr", "jsonlite"))
- Load libraries:
  - library(tidyverse)
  - library(httr)
  - library(jsonlite)

- Save your OpenAI API key (recommended):
  - Sys.setenv(OPENAI_API_KEY = "your-key-here")
  - Or place in ~/.Renviron: OPENAI_API_KEY=your-key-here

- OpenAI Chat API endpoint:
  - endpoint <- "https://api.openai.com/v1/chat/completions"

- System prompt (shared persona for all prompts):
  - system_msg <- "You are a witty data-science meme generator. Produce a single concise meme caption tailored to the given meme template and concept. Keep it under 200 characters. If possible, reference the meme template by name in the caption."

R function to call the API
- This function sends a chat-style prompt to gpt-3.5-turbo (or another model), returns the caption and usage data.

- Code (paste into an R script or R Markdown cell):

```r
library(httr)
library(jsonlite)
library(tidyverse)

endpoint <- "https://api.openai.com/v1/chat/completions"

system_msg <- "You are a witty data-science meme generator. Produce a single concise meme caption tailored to the given meme template and concept. Keep it under 200 characters. If possible, reference the meme template by name in the caption."

make_openai_call <- function(prompt_text, model = "gpt-3.5-turbo", temperature = 0.6, max_tokens = 180) {
  body <- list(
    model = model,
    messages = list(
      list(role = "system", content = system_msg),
      list(role = "user", content = prompt_text)
    ),
    temperature = temperature,
    max_tokens = max_tokens,
    n = 1
  )
  
  res <- POST(
    endpoint,
    add_headers(Authorization = paste("Bearer", Sys.getenv("OPENAI_API_KEY"))),
    content_type_json(),
    body = toJSON(body, auto_unbox = TRUE)
  )
  
  stop_for_status(res)
  raw <- content(res, as = "text", encoding = "UTF-8")
  parsed <- fromJSON(raw, flatten = TRUE)
  caption <- parsed$choices[[1]]$message$content
  usage <- parsed$usage
  list(caption = caption, usage = usage)
}
```

Data: define prompts using meme templates and topics
- Create a small data frame of meme templates and data-science topics you want to explain or illustrate.

```r
prompts <- tibble(
  id = 1:6,
  template = c("Doge", "Distracted Boyfriend", "Two-Button", "Expanding Brain", "Drake Hotline Bling", "Futurama Fry"),
  topic = c("gradient descent", "overfitting vs. underfitting", "cross-validation", "p-values vs. confidence intervals", "feature engineering vs. baselines", "Bayesian updating")
)

prompts <- prompts %>% 
  mutate(prompt = paste0(
    "Explain ", topic, " in the style of the ", template, " meme. ",
    "Provide a single concise caption suitable for a slide or social post. ",
    "Reference the meme name where appropriate."
  ))
```

- Optional: print prompts to inspect
```r
prompts
```

Step-by-step activity (30–60 minutes, depending on group size)
1) Generate meme captions
- For every row in prompts, call the API and store the result.

```r
prompts <- prompts %>%
  mutate(result = map(prompt, ~ {
    Sys.sleep(0.5)  # gently rate-limit if running many prompts
    make_openai_call(.x)
  }))

# Unnest the results into tidy columns
results_tbl <- prompts %>%
  mutate(
    caption = map_chr(result, "caption"),
    usage = map(result, "usage")
  ) %>%
  select(-result) %>%
  unnest_wider(usage)

# If unnest_wider(usage) doesn't work due to structure, you can do:
# results_tbl <- prompts %>% mutate(ut = map(usage, ~ as.list(.x))) %>% unnest_wider(ut)
```

2) Quick quality checks (tidyverse style)
- Basic metadata
```r
results_tbl <- results_tbl %>%
  mutate(
    word_count = str_count(caption, "\\S+"),
    char_count = str_length(caption)
  )
```

- Summaries
```r
results_tbl %>% 
  select(id, template, topic, caption, word_count, char_count) %>%
  arrange(id)
```

3) Visualize meme captions (analysis and communication)
- Caption length by meme template (for engagement intuition)
```r
ggplot(results_tbl, aes(x = template, y = word_count, fill = template)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(title = "Caption length by meme template",
       x = "Meme template",
       y = "Word count") +
  theme_minimal()
```

- Optional: distribution of token usage vs caption length (if you want to explore API costs)
```r
results_tbl %>% 
  ggplot(aes(x = total_tokens, y = word_count)) +
  geom_point(alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  labs(title = "API usage vs caption length",
       x = "Total tokens used",
       y = "Caption word count")
```
Note: The usage data typically includes prompt_tokens, completion_tokens, total_tokens depending on model version.

4) Create a Memeboard (deliverable)
- Save a cute, shareable table of the best captions and their metrics
```r
memeboard <- results_tbl %>%
  select(id, template, topic, caption, word_count, total_tokens) %>%
  arrange(desc(word_count), total_tokens)

write_csv(memeboard, "memeboard.csv")
```

5) Optional refinement: prompt experiment
- If you have budget or want to compare prompts, duplicate the prompt column and add a variant prompt_variant (e.g., more or less humorous, or ask for 2 options). Run API calls again and compare captions and token usage.

6) Reflection prompts (for students)
- Which meme template produced the most informative caption for the concept?
- Did any prompts produce overly long captions or ambiguous captions?
- How did token usage vary by template or topic? What does this imply for cost-performance trade-offs?

Clean-up and best practices
- Respect rate limits and costs: insert small sleeps (e.g., Sys.sleep(0.5) between calls).
- Handle errors gracefully: wrap API calls in tryCatch to collect failed prompts for retry.
- Keep API keys secure: do not hard-code keys in scripts; rely on environment variables or .Renviron.
- Version control: track API prompts and results, but avoid sharing sensitive keys in repos.
- Reproducibility: pin a fixed seed for any randomness (if you add random prompts or sampling).

Optional extensions (for more advanced groups)
- Use a different model with higher quality (e.g., gpt-4-turbo if available; note cost).
- Run a mini A/B test: compare two different system prompts or two different prompts for the same topic; analyze which produces captions with higher readability or perceived humor (students can rate captions on a scale).
- Add sentiment or readability proxy metrics:
  - Basic readabilty proxy: word_count, sentence_count (if captions contain punctuation), average word length.
  - If you want more, bring in a simple Flesch-Kincaid-like proxy or use an external package for readability (e.g., quanteda or textstat, if you install extra packages).

Deliverables for the course
- A single R script or R Markdown notebook containing:
  - Setup code (library load, API key handling, endpoint, system prompt).
  - Data frame of prompts (meme templates and topics).
  - The API call function (make_openai_call).
  - The tidyverse pipeline to collect, unnest, and analyze results.
  - Visualizations (caption length by meme template, token usage vs length).
  - The Memeboard export (CSV) with the best captions and metrics.
  - Short reflective prompts or discussion questions.

Assessment rubric (quick guide)
- API integration (40%): correct API call wiring, error handling, and response parsing.
- Data wrangling (25%): tidy data frame construction, proper use of purrr and tidyr to flatten nested results.
- Analysis and visualization (20%): meaningful metrics (length, token usage) and clear visuals.
- Reproducibility and hygiene (10%): secure key handling, clear setup instructions, and an executable script.
- Creativity and engagement (5%): meme-tastic prompts that are both entertaining and educational.

Example outputs (mocked for illustration)
- Caption example 1 (Doge, gradient descent): "Much descent. Very converge. Wow, optimization done."
- Caption example 2 (Distracted Boyfriend, overfitting): "Boyfriend = model; Girlfriend = training data; New girl = real world. Overfit, whoops."
- Caption example 3 (Two-Button, cross-validation): "Yes: Reboot model with CV. No: Stay with train/test split."
- Caption example 4 (Expanding Brain, p-values): "Brain grows: p < .05 means significance. Brain bigger: confidence intervals tell the story."

Safety and costs note
- OpenAI API usage costs can accumulate quickly with many prompts; manage prompts and max_tokens intentionally.
- Do not share or hard-code API keys; use environment variables.
- Ensure prompts adhere to your institution’s safety and ethics guidelines; consider adding a brief discussion on bias, reliability, and the limitations of AI-generated explanations.

If you’d like, I can tailor the prompts to your graduate course topics (e.g., statistics, ML theory, NLP, causal inference) or provide a ready-to-run R Markdown file with all steps pre-woven.
