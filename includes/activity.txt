Meme-tastic Data Science with OpenAI in the Tidyverse

Course vibe: graduate-level, hands-on, goofy but rigorous. Students will design prompts, make API calls, manage and tidy the AI responses with the Tidyverse, and analyze the results with text and data visualization tools. The activity uses OpenAI’s chat/completions API to generate meme captions in different meme voices, then analyzes caption length, word usage, and stylistic signals.

Learning objectives
- Understand how to call OpenAI’s API from R and incorporate API results into tidyverse pipelines.
- Design prompt templates that yield structured outputs (e.g., JSON arrays) for easy parsing in R.
- Build robust data workflows: API calls, response parsing, error handling, and result caching.
- Perform text analysis and visualization on AI-generated content (tokenization, basic sentiment/linguistic signals, readability proxies).
- Compare variations across meme templates and styles, and communicate insights with reproducible code and visuals.
- Reflect on prompt design, model behavior, biases, and ethical considerations in AI-assisted storytelling.

Prerequisites
- R (>= 4.1) and RStudio (or equivalent).
- Basic familiarity with dplyr, tidyr, purrr, ggplot2, and tidytext in the Tidyverse.
- OpenAI API key (set as OPENAI_API_KEY in your environment).
- Packages: httr, jsonlite, dplyr, tidyr, purrr, ggplot2, stringr, readr, tidytext, tibble, and optionally an OpenAI helper package if you prefer (see code below for both approaches).

Materials
- A small dataset of meme templates and context (8–12 examples recommended).
- An OpenAI account with API access.
- Optional: a rubric for humor or quality of captions (students can provide or you can supply a starter rubric).

Activity outline (modular)
1) Warm-up: Meme prompt design (20–30 minutes)
- Goal: brainstorm how to prompt a model to produce captions in the voice of a specific meme.
- Deliverable: a plan for 3 prompts, each targeting a different meme voice (e.g., Distracted Boyfriend, Drake Hotline Bling, Grumpy Cat, etc.).
- Practice: discuss how temperature, max_tokens, and prompt style influence the output.

2) Data setup and API call scaffold (40–60 minutes)
- Build a small data frame of meme templates, contexts, and desired voice/style.
- Write a reusable API call function (with error handling and optional backoff).
- Generate 3 captions per meme via the API, returning a tidy data frame with meme_id, caption_id, caption_text, and metadata.

3) Response handling and tidy data wrangling (30–45 minutes)
- Normalize and clean the API output (trim whitespace, remove stray quotes, etc.).
- Tokenize captions, remove stop words, and compute simple metrics (word counts, caption length, unique word counts).
- Compute a simple readability proxy (e.g., caption word count as a stand-in for complexity) and a basic sentiment/skew metric if you want to extend (optional).

4) Analysis and visualization (45–60 minutes)
- Compare caption characteristics across meme templates and voice styles.
- Visualize distributions of caption lengths, most common words, and cross-template comparisons.
- Optional: cluster captions by lexical similarity or frequency profiles.

5) Discussion and reflection (20–30 minutes)
- Interpret which prompts/styles yielded the most engaging captions (as measured by your rubric or by audience feedback).
- Discuss limitations, biases, and ethical considerations in using AI to generate humorous content.

6) Extension ideas (optional)
- Compare results across different OpenAI models (gpt-3.5-turbo vs gpt-4-turbo) and temperature settings.
- Introduce a human-in-the-loop evaluation step where students rate a subset of captions.
- Build an automated report (RMarkdown) that grooves from data to visuals to interpretation.

Sample dataset (memes)
- Meme templates: "Distracted Boyfriend", "Drake Hotline Bling", "Grumpy Cat", "Two Buttons", "Expanding Brain", "Success Kid", "Philosoraptor", "Funny Cat with Keyboard"
- Contexts: brief scenario describing a data-science or AI-ish situation (e.g., choosing between model interpretability and performance; data wrangling annoyances; pipeline failures).
- Prompt style: lighthearted, meme-voice instructions (e.g., “Drake style”, “Philosoraptor tone”, etc.)

Code skeleton (R, Tidyverse, OpenAI API)
- This scaffold shows two approaches to calling the API: (A) using an OpenAI R package (if installed) or (B) using httr directly. It also demonstrates a tidy workflow to generate, parse, and analyze captions.

Setup and libraries
```r
# Install (if needed)
# install.packages(c("httr","jsonlite","dplyr","tidyr","purrr","ggplot2","stringr","readr","tidytext","tibble","forcats","textdata"))

library(httr)
library(jsonlite)
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
library(stringr)
library(readr)
library(tidytext)
library(tibble)
library(forcats)

# OpenAI API key (recommended: set in environment)
# Sys.setenv(OPENAI_API_KEY = "sk-...")
```

Option A: Using an OpenAI R package (if available)
```r
# If you have an OpenAI package installed (e.g., openai), you can use this approach.
# If not, skip to Option B below.

# library(openai)

# prompt_texts <- ... (as constructed below)
# model <- "gpt-3.5-turbo"  # or "gpt-4-turbo"

# generate captions for a given prompt
# captions <- lapply(prompt_texts, function(pt) {
#   res <- openai::create_chat_completion(model = model,
#                                        messages = list(list(role="user", content = pt)),
#                                        temperature = 0.7)
#   content <- res$choices[[1]]$message$content
#   jsonlite::fromJSON(content)
# })

```

Option B: Direct API call with httr (works anywhere)
```r
# Build a helper to call chat/completions
call_openai_chat <- function(prompt_text,
                             model = "gpt-3.5-turbo",
                             max_tokens = 512,
                             temperature = 0.7) {
  req <- POST(
    url = "https://api.openai.com/v1/chat/completions",
    add_headers(Authorization = paste("Bearer", Sys.getenv("OPENAI_API_KEY"))),
    content_type_json(),
    body = toJSON(list(
      model = model,
      messages = list(list(role = "user", content = prompt_text)),
      max_tokens = max_tokens,
      temperature = temperature
    ), auto_unbox = TRUE)
  )
  stop_for_status(req)
  cont <- content(req, as = "text", encoding = "UTF-8")
  json <- jsonlite::fromJSON(cont)
  json$choices[[1]]$message$content
}

# Example meme prompts (we'll construct this in a data frame)
```

Prompt construction and data pipeline (end-to-end)
```r
# Example meme data
memes <- tibble(
  id = 1:6,
  meme = c("Distracted Boyfriend", "Drake Hotline Bling", "Grumpy Cat",
           "Two Buttons", "Expanding Brain", "Success Kid"),
  context = c(
    "A data scientist must choose between model interpretability and raw performance.",
    "When your model finally outperforms tradition baselines.",
    "A cat complains about poor data quality.",
    "Choosing between 'reproducible code' and 'quick demo'.",
    "A progress from simple to complex data understanding.",
    "A small data-cleaning win that changes everything."
  ),
  style = c("Dramatic, humorous", "Ironically optimistic", "Sarcastic, grumpy",
            "Crisp, simple", "Epic, science-fiction tone", "Sincere, celebratory")
)

# Build prompts: ask for 3 captions per meme in a JSON array
prompts_df <- memes %>%
  mutate(prompt_text = pmap_chr(
    list(meme, context, style),
    function(template, ctx, sty) {
      paste0(
        "You are Meme Master AI. Create 3 funny captions for the meme template '",
        template, "' with context: ", ctx, ". Style: ", sty,
        ". Output: a JSON array of 3 strings, e.g., [\"caption1\",\"caption2\",\"caption3\"]."
      )
    }
  ))

prompts_df
```

API calls to generate captions (per prompt)
```r
# For each meme, call the API with its prompt_text and collect 3 captions
captions_df <- map2_df(prompts_df$id, prompts_df$prompt_text, ~ {
  mid <- .x
  prompt <- .y
  caps <- try(call_openai_chat(prompt_text = prompt), silent = TRUE)
  if (inherits(caps, "try-error") || is.null(caps)) {
    caps <- c("[\"Error fetching caption1\"]")
  }
  # If the API returns a plain string, try to parse as JSON array; else fallback
  parsed <- try(jsonlite::fromJSON(as.character(caps)), silent = TRUE)
  if (inherits(parsed, "try-error") || !is.vector(parsed)) {
    # Fallback: wrap the raw output
    parsed <- as.character(caps)
  }
  tibble(
    id = mid,
    caption_id = 1:length(parsed),
    caption = unlist(parsed)
  )
})

captions_df
```

Combine with meme metadata (optional)
```r
results <- captions_df %>%
  left_join(memes, by = c("id" = "id")) %>%
  select(id, meme, context, style, caption_id, caption)
results
```

Basic analysis: lengths, tokenization, and word usage
```r
# Caption length (in words)
results <- results %>%
  mutate(word_count = str_count(caption, "\\S+"))

# Tokenize captions for word counts and most common terms
tokens <- results %>%
  unnest_tokens(word, caption)

stop_words <- tidytext::stop_words
tokens_nostop <- tokens %>% anti_join(stop_words, by = "word")

word_counts <- tokens_nostop %>%
  count(word, sort = TRUE) %>%
  head(20)

word_counts

# Readability proxy: simple word-count distribution by meme
lengths <- results %>%
  group_by(meme) %>%
  summarize(avg_words = mean(word_count),
            med_words = median(word_count),
            n = n())

lengths
```

Visualizations (example)
```r
# Average caption length by meme
ggplot(lengths, aes(x = fct_reorder(meme, avg_words), y = avg_words)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Average caption length by meme",
       x = "Meme",
       y = "Average words per caption")

# Top words across all captions
ggplot(word_counts, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "tomato") +
  coord_flip() +
  labs(title = "Top non-stopword terms in AI-generated captions",
       x = "Word", y = "Frequency")

# Optional: distribution of word counts
ggplot(results, aes(x = word_count)) +
  geom_histogram(binwidth = 1, fill = "goldenrod", color = "black") +
  labs(title = "Distribution of caption lengths (in words)", x = "Word count", y = "Frequency")
```

Extensions and alternative analyses
- Style comparisons: group by style and compare caption characteristics (length, sentiment proxies if you add them).
- Model comparison: repeat the API calls with "gpt-4-turbo" (if available) and compare outputs.
- Human rubric: Have students rate a subset of captions on humor, coherence, and meme-faithfulness, then compute inter-rater reliability.
- Reproducibility: save prompts and results to CSV/Parquet and share a small RMarkdown report.

Notes on error handling and best practices
- Rate limits: implement a backoff strategy if you expect many calls (e.g., on 429 responses). A simple pause and retry loop can help.
- Caching: store results locally (e.g., readr::write_rds) so you don’t re-call the API on every run.
- Prompt hygiene: alternate templates and prompts to reduce prompt drift and to study prompt design effects.
- Ethics and bias: be mindful of humor fairness, stereotypes, and potential harmful content. Include a debrief on bias and responsible AI usage.

What to deliver (grading/assessment)
- A reproducible R script or R Markdown document that:
  - Creates the meme dataset and prompts.
  - Calls the OpenAI API (with a robust error-handling strategy).
  - Parses and tidies the response into a clean data frame.
  - Produces at least two informative visualizations.
  - Includes a brief interpretation discussing what the prompts likely influenced and what was surprising or limiting.
- A short reflective write-up (1–2 pages) addressing:
  - Which prompt design choices yielded the most engaging captions and why.
  - How you would improve the workflow for larger datasets or different meme styles.
  - Ethical considerations and potential biases.

Safety and compliance reminder
- Do not share your OpenAI API keys in public repositories.
- Respect rate limits and usage guidelines.
- Be mindful of content policy when generating memes, ensuring captions avoid hate speech or explicit content.

If you’d like, I can tailor the meme templates to your course’s field (e.g., finance, bioinformatics, social science) or provide a ready-to-run RStudio project skeleton with a pre-populated meme dataset and a one-click script to execute the full workflow.
